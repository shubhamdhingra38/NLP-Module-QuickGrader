{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming text is preprocessed then applying these\n",
    "def num_of_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def average_word_length(text):\n",
    "    return len(text)/num_of_words(text)\n",
    "\n",
    "def pos_tagging(text):\n",
    "    #get the frequency of each tag after NER\n",
    "    words=text.split()\n",
    "    tagged=nltk.pos_tag(words)\n",
    "    result=[]\n",
    "    freq=defaultdict(int)\n",
    "    for word, noun in tagged:\n",
    "        freq[noun]+=1\n",
    "    return freq\n",
    "\n",
    "#maybe use the average score over previous X tests. could be a good feature for clustering\n",
    "# def get_average_score():\n",
    "#     pass\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.85, min_df=1, max_features=5000, stop_words='english')\n",
    "\n",
    "\n",
    "# documentA = 'the man went out for a walk and then sat'\n",
    "# documentB = 'the children sat around the fire'\n",
    "# vectors = vectorizer.fit_transform([documentA, documentB])\n",
    "# vectorizer.get_feature_names()\n",
    "def generate_vectors(documents):\n",
    "#     print(vectorizer.max_df)\n",
    "    vectorizer.fit(documents)\n",
    "    return vectorizer.transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'NNP': 3, 'NN': 1, 'IN': 1, 'VBP': 2, 'PRP': 1})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging(\"Hello world, from India! How are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.375"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_word_length(\"Hello world, from India! How are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/plasticityai/magnitude#using-the-library\n",
    "from pymagnitude import *\n",
    "vectors = Magnitude(\"glove-lemmatized.6B.100d.magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336951"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0194448,  0.1029267,  0.0693665,  0.0018058,  0.0794503,\n",
       "       -0.2790355, -0.0184297, -0.0963583,  0.07153  ,  0.0857471,\n",
       "        0.0297684, -0.1342948, -0.0147681, -0.0501425,  0.0175402,\n",
       "       -0.0753504,  0.1229656,  0.0498725, -0.0186124, -0.0211477,\n",
       "       -0.11231  , -0.0957562,  0.1035812,  0.0289361,  0.0347452,\n",
       "        0.0472991,  0.0886731,  0.0249267, -0.1134489,  0.0550827,\n",
       "       -0.1398767,  0.1949245, -0.1753384,  0.0122737,  0.0216179,\n",
       "       -0.0596497, -0.0874214, -0.0324387, -0.0392009, -0.0590889,\n",
       "       -0.0621913, -0.1211229, -0.126797 , -0.0517564, -0.126689 ,\n",
       "       -0.0972399,  0.081887 ,  0.1497683,  0.0316063, -0.0867621,\n",
       "       -0.0007265,  0.0148413, -0.013114 ,  0.1139668,  0.0566093,\n",
       "       -0.2743653, -0.051048 ,  0.0340383,  0.3492153, -0.049998 ,\n",
       "       -0.0215654,  0.0475135, -0.0243294,  0.0678574, -0.0370739,\n",
       "        0.0505841,  0.083798 ,  0.0059875,  0.1437273,  0.1300566,\n",
       "        0.0436217,  0.0419268, -0.0219578, -0.0723243, -0.0898899,\n",
       "       -0.0694412,  0.0624391, -0.0244486, -0.1043198, -0.0483777,\n",
       "        0.2191968,  0.0147098, -0.0830498, -0.0076068, -0.3014333,\n",
       "        0.1170024,  0.1338055, -0.1053984, -0.0112655, -0.0674619,\n",
       "        0.0805241, -0.0009741,  0.018147 ,  0.0055359, -0.0325213,\n",
       "        0.042289 ,  0.0055448, -0.1146641,  0.1696515,  0.0488717],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.query(\"technology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "answers=[\n",
    "    'the combination of a clash symbol be accompany by a bass drum play an dent part played loudly',\n",
    "    'it strategy location and excellent infrastructure with the largest airport in scandinavian local 14 minutes by train from the city centre',\n",
    "    'a threshold flute made from a mammoth tusk and two flutes made from swans bones are among the oldest known music instruments']\n",
    "try:\n",
    "    tfidf_vec=generate_vectors(answers)\n",
    "except ValueError:\n",
    "    vectorizer=TfidfVectorizer(max_df=1.00, min_df=1, max_features=5000, stop_words='english')\n",
    "    tfidf_vec=generate_vectors(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "answers=[\n",
    "    'delhi is the capital of india',\n",
    "    'the capital of india is delhi',\n",
    "    'this is something unrelated']\n",
    "try:\n",
    "    tfidf_vec=generate_vectors(answers)\n",
    "except ValueError:\n",
    "    vectorizer=TfidfVectorizer(max_df=1.00, min_df=1, max_features=5000)\n",
    "    tfidf_vec=generate_vectors(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capital',\n",
       " 'delhi',\n",
       " 'india',\n",
       " 'is',\n",
       " 'of',\n",
       " 'something',\n",
       " 'the',\n",
       " 'this',\n",
       " 'unrelated']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_weighted_avg_vec(para, idx):\n",
    "    s=0\n",
    "    for i, word in enumerate(para.split(' ')):\n",
    "        weight=tfidf_vec[idx].toarray().flatten()[i]\n",
    "        v=weight*vectors.query(word)\n",
    "        s+=v\n",
    "    s/=len(para.split(' '))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'delhi is the capital of india'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999994 0.98323834]\n",
      " [0.98323834 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "v1=tfidf_weighted_avg_vec(answers[0], 0)\n",
    "v2=tfidf_weighted_avg_vec(answers[1], 1)\n",
    "print(cosine_similarity([v1, v2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
